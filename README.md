# ğŸ¤– Bixby ChatBot

Há»‡ thá»‘ng ChatBot AI thÃ´ng minh vá»›i kháº£ nÄƒng chat text vÃ  voice, há»— trá»£ tiáº¿ng Viá»‡t.

## âœ¨ TÃ­nh nÄƒng chÃ­nh

- ğŸ¤– **AI Chat**: Ollama (Gemma2, Gemma3N) vá»›i fallback thÃ´ng minh
- ğŸ¤ **Voice Chat**: Nháº­n diá»‡n giá»ng nÃ³i vÃ  chuyá»ƒn Ä‘á»•i text-to-speech
- ğŸ’¬ **Conversation Management**: Quáº£n lÃ½ lá»‹ch sá»­ chat vá»›i database
- ğŸŒ **Modern Web UI**: Dark theme, responsive design
- ğŸ³ **Docker Deployment**: One-click deployment vá»›i auto-setup
- ğŸ”„ **Auto Fallback**: Tá»± Ä‘á»™ng chuyá»ƒn Ä‘á»•i giá»¯a cÃ¡c AI provider

## ğŸš€ Quick Start

### CÃ¡ch 1: Docker (Khuyáº¿n nghá»‹)

```bash
# Clone repository
git clone <repository-url>
cd ChatBot

# Start vá»›i Docker Compose
docker-compose up -d

# Truy cáº­p á»©ng dá»¥ng
# Frontend: http://localhost:3000
# Backend API: http://localhost:8000
# API Docs: http://localhost:8000/docs
```

### CÃ¡ch 2: Development

```bash
# Backend
cd backend
pip install -r requirements.txt
python main.py

# Frontend (terminal má»›i)
cd frontend
npm install
npm start
```

## ğŸ—ï¸ Kiáº¿n trÃºc há»‡ thá»‘ng

```
ChatBot/
â”œâ”€â”€ backend/               # FastAPI Python backend
â”‚   â”œâ”€â”€ api/              # REST API endpoints
â”‚   â”œâ”€â”€ services/         # AI, Voice, Database services
â”‚   â”œâ”€â”€ config/           # Configuration & database
â”‚   â””â”€â”€ data/             # SQLite DB & models
â”œâ”€â”€ frontend/             # React TypeScript frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/   # UI components
â”‚   â”‚   â”œâ”€â”€ hooks/        # Custom React hooks
â”‚   â”‚   â””â”€â”€ utils/        # Helper functions
â””â”€â”€ scripts/              # Deployment & utility scripts
```

## ğŸ”§ Configuration

### Docker Compose (docker-compose.yml)

Há»‡ thá»‘ng tá»± Ä‘á»™ng cáº¥u hÃ¬nh vá»›i cÃ¡c environment variables:

```yaml
environment:
  # AI Configuration
  - PREFERRED_AI_PROVIDER=ollama
  - OLLAMA_MODEL=gemma2:2b
  - OLLAMA_FALLBACK_MODEL=gemma3n:e4b
  
  # Voice Configuration
  - VOSK_MODEL_PATH=/app/data/models/vosk-vi
  - VOSK_LANGUAGE=vi
  
  # Auto Setup
  - AUTO_SETUP_ENABLED=true
  - DOWNLOAD_MODELS_ON_START=true
```

### Manual Configuration

#### Backend (backend/config.json)
```json
{
  "ai": {
    "preferred_provider": "ollama",
    "ollama_model": "gemma2:2b",
    "fallback_enabled": true
  },
  "voice": {
    "vosk_model_path": "/app/data/models/vosk-vi",
    "language": "vi-VN"
  }
}
```

#### Frontend (.env)
```bash
REACT_APP_API_URL=http://localhost:8000
REACT_APP_WS_URL=ws://localhost:8000
```

## ğŸ“¡ API Endpoints

### System Health
- `GET /api/health` - System health check
- `GET /models/status` - AI models status
- `GET /api/voice/capabilities` - Voice service status

### Chat Features
- `POST /chat/message` - Send message to AI
- `GET /chat/history` - Get conversation history
- `POST /voice/transcribe` - Audio to text transcription

### Conversation Management
- `POST /api/conversations` - Create conversation
- `PUT /api/conversations/{id}/title` - Update title
- `DELETE /api/conversations/{id}` - Delete conversation

## ğŸ¤– AI Models

### Ollama Models (Default)
- **Gemma2 2B**: Fast, lightweight, good for basic chat
- **Gemma3N E4B**: Advanced model, better understanding

### Auto-Setup Features
- Tá»± Ä‘á»™ng download vÃ  cÃ i Ä‘áº·t Ollama
- Download AI models automatically
- Setup Vosk Vietnamese model
- Database initialization

## ğŸ¤ Voice Features

### Speech Recognition
- **Vosk**: Offline Vietnamese recognition
- **Google Speech API**: Online fallback
- **Browser SpeechRecognition**: Web API fallback

### Text-to-Speech
- **pyttsx3**: Server-side TTS
- **Browser speechSynthesis**: Client-side TTS
- Vietnamese voice support

### Voice Settings
- Language selection (vi-VN, en-US, ja-JP, ko-KR)
- Speech speed control
- Auto-speak responses
- Voice-to-voice conversation

## ğŸ—„ï¸ Database

### SQLite Database
- **conversations**: Chat sessions
- **messages**: Individual messages vá»›i metadata
- **Auto-backup**: Persistent volumes

### Database Schema
```sql
-- Conversations
CREATE TABLE conversations (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    title TEXT NOT NULL,
    started_at DATETIME DEFAULT CURRENT_TIMESTAMP
);

-- Messages
CREATE TABLE messages (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    conversation_id INTEGER REFERENCES conversations(id),
    sender TEXT NOT NULL,
    content TEXT NOT NULL,
    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
    ai_provider TEXT,
    ai_model TEXT
);
```

## ğŸ¨ Frontend Features

### Modern UI/UX
- **Dark Theme**: Easy on the eyes
- **Responsive Design**: Mobile, tablet, desktop
- **Real-time Chat**: Instant AI responses
- **Voice Controls**: One-click recording

### Advanced Features
- **Provider Selection**: Choose AI model
- **Health Monitoring**: System status indicators
- **Voice Diagnostics**: Audio quality checking
- **Conversation Management**: Edit titles, delete chats

## ğŸ³ Docker Deployment

### Production Deployment

```bash
# Production build
docker-compose -f docker-compose.prod.yml up -d

# Scaling
docker-compose up -d --scale backend=2

# Monitoring
docker-compose logs -f backend
docker stats
```

### Resource Requirements
- **Memory**: 3-8GB (depending on AI model)
- **CPU**: 2-4 cores recommended
- **Storage**: 10GB+ for models and database
- **Network**: Internet for model downloads

### Health Checks
```bash
# System health
curl http://localhost:8000/api/health

# Models status  
curl http://localhost:8000/models/status

# Voice capabilities
curl http://localhost:8000/api/voice/capabilities
```

## ğŸ”„ Development

### Backend Development
```bash
cd backend
python -m venv venv
source venv/bin/activate  # Linux/Mac
pip install -r requirements.txt
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

### Frontend Development
```bash
cd frontend
npm install
npm start
# Runs on http://localhost:3000
```

### Testing
```bash
# Backend tests
cd backend
python -m pytest

# Frontend tests
cd frontend
npm test

# System integration test
./scripts/test_system.sh
```

## ğŸ› Troubleshooting

### Common Issues

#### 1. Backend khÃ´ng khá»Ÿi Ä‘á»™ng
```bash
# Check logs
docker-compose logs backend

# Common fixes
docker-compose restart backend
docker system prune  # Clear cache
```

#### 2. AI Model lá»—i memory
```bash
# Use smaller model
# In docker-compose.yml:
OLLAMA_MODEL=gemma2:2b  # Instead of gemma3n:e4b

# Increase memory limit
deploy:
  resources:
    limits:
      memory: 8G
```

#### 3. Voice khÃ´ng hoáº¡t Ä‘á»™ng
```bash
# Check browser permissions (microphone)
# Verify HTTPS connection (required for getUserMedia)
# Check voice service status:
curl http://localhost:8000/api/voice/capabilities
```

#### 4. Database locked
```bash
# Stop containers
docker-compose down

# Remove database locks
sudo rm -f ./backend/data/chatbot.db-wal
sudo rm -f ./backend/data/chatbot.db-shm

# Restart
docker-compose up -d
```

### Debug Mode

#### Enable debug logging
```bash
# Backend
export LOG_LEVEL=DEBUG

# Frontend
localStorage.setItem('debug', 'true');
```

#### Health checks
```bash
# Test script
./scripts/test_system.sh

# Manual checks
curl http://localhost:8000/api/health
curl http://localhost:3000  # Should show React app
```

## ğŸ“ˆ Performance Tips

### Resource Optimization
1. **Use appropriate AI model**: gemma2:2b cho basic chat, gemma3n:e4b cho advanced
2. **Limit conversation history**: Set max messages per conversation
3. **Enable model caching**: Faster subsequent responses
4. **Use SSD storage**: Better I/O for database operations

### Scaling Options
```bash
# Horizontal scaling
docker-compose up -d --scale backend=2

# Load balancer (nginx)
# Add nginx container to docker-compose.yml
```

## ğŸ”’ Security

### Data Protection
- SQLite database vá»›i file permissions
- No API keys trong code
- Input validation on all endpoints
- CORS configured cho frontend only

### Privacy
- Voice data processed locally khi cÃ³ thá»ƒ
- No permanent audio storage
- Conversation data stays on your server

## ğŸ“š Documentation

### Detailed Documentation
- [Backend README](./backend/README.md) - API, services, configuration
- [Frontend README](./frontend/README.md) - UI components, state management
- [Docker Documentation](./docker-compose.yml) - Deployment configuration

### API Documentation
- Swagger UI: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc

## ğŸ¤ Contributing

### Development Setup
1. Fork repository
2. Create feature branch
3. Make changes
4. Test thoroughly
5. Submit pull request

### Code Style
- **Backend**: Black formatting, type hints
- **Frontend**: Prettier, TypeScript strict mode
- **Commits**: Conventional commits format

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- **Ollama**: Local AI model serving
- **Vosk**: Offline speech recognition
- **React**: Modern frontend framework
- **FastAPI**: High-performance Python API framework
- **Docker**: Containerization platform

---

## ğŸ†˜ Support

Náº¿u báº¡n gáº·p váº¥n Ä‘á»:

1. **Check logs**: `docker-compose logs backend`
2. **Run health check**: `curl http://localhost:8000/api/health`
3. **Restart services**: `docker-compose restart`
4. **Clear cache**: `docker system prune -a`

**System Requirements**: 4GB+ RAM, 10GB+ storage, modern browser with microphone support.