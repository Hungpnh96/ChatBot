#!/usr/bin/env python3
"""
Script Ä‘á»ƒ cÃ i Ä‘áº·t model gemma3n:e4b cho Ollama
"""

import requests
import json
import time
import sys
import os

def check_ollama_server():
    """Kiá»ƒm tra Ollama server cÃ³ cháº¡y khÃ´ng"""
    try:
        response = requests.get("http://localhost:11434/api/tags", timeout=5)
        return response.status_code == 200
    except:
        return False

def get_installed_models():
    """Láº¥y danh sÃ¡ch models Ä‘Ã£ cÃ i Ä‘áº·t"""
    try:
        response = requests.get("http://localhost:11434/api/tags")
        if response.status_code == 200:
            data = response.json()
            return [model['name'] for model in data.get('models', [])]
        return []
    except:
        return []

def install_model(model_name):
    """CÃ i Ä‘áº·t model"""
    print(f"Äang cÃ i Ä‘áº·t model {model_name}...")
    
    try:
        # Gá»i API Ä‘á»ƒ pull model
        response = requests.post(
            "http://localhost:11434/api/pull",
            json={"name": model_name},
            stream=True
        )
        
        if response.status_code == 200:
            print("Äang táº£i model (cÃ³ thá»ƒ máº¥t vÃ i phÃºt)...")
            
            for line in response.iter_lines():
                if line:
                    try:
                        data = json.loads(line.decode('utf-8'))
                        if 'status' in data:
                            print(f"Status: {data['status']}")
                        if 'completed_at' in data:
                            print(f"HoÃ n thÃ nh: {data['completed_at']}")
                            break
                    except json.JSONDecodeError:
                        continue
            
            print(f"âœ… Model {model_name} Ä‘Ã£ Ä‘Æ°á»£c cÃ i Ä‘áº·t thÃ nh cÃ´ng!")
            return True
        else:
            print(f"âŒ Lá»—i khi cÃ i Ä‘áº·t model: {response.status_code}")
            return False
            
    except Exception as e:
        print(f"âŒ Lá»—i: {e}")
        return False

def main():
    """Main function"""
    print("ğŸš€ Bixby Chatbot - Setup Gemma3n:e4b Model")
    print("=" * 50)
    
    # Kiá»ƒm tra Ollama server
    print("1. Kiá»ƒm tra Ollama server...")
    if not check_ollama_server():
        print("âŒ Ollama server khÃ´ng cháº¡y!")
        print("HÃ£y khá»Ÿi Ä‘á»™ng Ollama trÆ°á»›c:")
        print("  - macOS: brew install ollama && ollama serve")
        print("  - Linux: curl -fsSL https://ollama.ai/install.sh | sh && ollama serve")
        print("  - Windows: Táº£i tá»« https://ollama.ai/download")
        sys.exit(1)
    
    print("âœ… Ollama server Ä‘ang cháº¡y")
    
    # Kiá»ƒm tra models Ä‘Ã£ cÃ i Ä‘áº·t
    print("\n2. Kiá»ƒm tra models Ä‘Ã£ cÃ i Ä‘áº·t...")
    installed_models = get_installed_models()
    print(f"Models hiá»‡n táº¡i: {', '.join(installed_models) if installed_models else 'KhÃ´ng cÃ³'}")
    
    # Kiá»ƒm tra gemma3n:e4b
    target_model = "gemma3n:e4b"
    if target_model in installed_models:
        print(f"âœ… Model {target_model} Ä‘Ã£ Ä‘Æ°á»£c cÃ i Ä‘áº·t!")
        return
    
    # CÃ i Ä‘áº·t model
    print(f"\n3. CÃ i Ä‘áº·t model {target_model}...")
    if install_model(target_model):
        print("\nğŸ‰ HoÃ n thÃ nh! Model Ä‘Ã£ sáºµn sÃ ng sá»­ dá»¥ng.")
        print("\nÄá»ƒ khá»Ÿi Ä‘á»™ng chatbot:")
        print("  cd ChatBot/backend")
        print("  python main.py")
    else:
        print("\nâŒ CÃ i Ä‘áº·t tháº¥t báº¡i!")
        sys.exit(1)

if __name__ == "__main__":
    main()
